{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course Work 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iY4SDtC5rE1M",
        "outputId": "b51a61ef-8bc6-4272-81ef-4e5b664b53df"
      },
      "source": [
        "!pip install sobol_seq\n",
        "!pip install tensorflow==1.15.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sobol_seq\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/df/6c4ad25c0b48545a537b631030f7de7e4abb939e6d2964ac2169d4379c85/sobol_seq-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sobol_seq) (1.19.5)\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.2.0\n",
            "Collecting tensorflow==1.15.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/99abd43185d94adaaaddf8f44a80c418a91977924a7bc39b8dacd0c495b0/tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.36.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.5) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=fa4babd40b24f59b73b53941f5150050f8c68aeca10faf4665998d06b4b612f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxn9Wy3uChKy"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "import tensorflow as tf\n",
        "from scipy.stats import norm\n",
        "import sobol_seq\n",
        "\n",
        "DTYPE = tf.float32\n",
        "\n",
        "class Compressible(object):\n",
        "    def __init__(self, name, message_freq=1000):\n",
        "        self.name = name\n",
        "        self.message_freq = message_freq\n",
        "        self.message_counter = 0\n",
        "\n",
        "    def get_feed_dict(self, validation=False):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_train_op(self, training):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def training_step(self, training, extra_ops):\n",
        "        self.message_counter += 1\n",
        "        if self.message_counter % self.message_freq == 0 or self.message_counter == 1:\n",
        "            loss, training_acc, kl, kl_loss = self.sess.run([self.loss, self.accuracy, self.mean_kl, self.kl_loss],\n",
        "                                                   feed_dict=self.get_feed_dict())\n",
        "\n",
        "            mean_validation_acc = 0.0\n",
        "            for i in range(10):\n",
        "                validation_acc = self.sess.run(self.accuracy,\n",
        "                                               feed_dict=self.get_feed_dict(validation=True))\n",
        "                mean_validation_acc += validation_acc\n",
        "            mean_validation_acc /= 10.\n",
        "            print(\"Iteration {}, Validation score = {}, Training score = {}, Loss = {}, KL-Loss = {}, KL_2 = {}\".format(\n",
        "                self.message_counter,\n",
        "                mean_validation_acc,\n",
        "                training_acc,\n",
        "                loss,\n",
        "                kl_loss,\n",
        "                kl / np.log(2.)))\n",
        "            path = '/scratch/mh740/compression_models/{}/{}/{}.ckpt'.format(self.name, training,\n",
        "                                                                         self.message_counter)\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "            self.saver.save(self.sess, path)\n",
        "\n",
        "        self.sess.run((self.get_train_op(training=training), extra_ops),\n",
        "                      feed_dict=self.get_feed_dict())\n",
        "\n",
        "    def train(self, iterations, enforce_kl):\n",
        "        if enforce_kl:\n",
        "            self.sess.run(self.enable_kl_loss.assign(1.))\n",
        "            with tf.control_dependencies([self.get_train_op(training='training')]):\n",
        "                extra_ops = [tf.identity(self.kl_penalty_update)]\n",
        "            for i in range(iterations):\n",
        "                self.training_step(training='training', extra_ops=extra_ops)\n",
        "        else:\n",
        "            self.sess.run(self.enable_kl_loss.assign(0.))\n",
        "            for i in range(iterations):\n",
        "                self.training_step(training='pretrain', extra_ops=[])\n",
        "        mean_validation_acc = 0.0\n",
        "        for i in range(20):\n",
        "            validation_acc = self.sess.run(self.accuracy,\n",
        "                                           feed_dict=self.get_feed_dict(validation=True))\n",
        "        mean_validation_acc += validation_acc\n",
        "        return mean_validation_acc / 20.\n",
        "\n",
        "    def compress(self, retrain_iter, kl_penalty_step=1.0005):\n",
        "        self.sess.run(self.kl_penalty_step.assign(kl_penalty_step))\n",
        "        n_blocks = self.fixed_weights.get_shape().as_list()[0]\n",
        "        self.sess.run(self.enable_kl_loss.assign(1.))\n",
        "        for i in range(n_blocks):\n",
        "            self.sess.run(self.comp_ops, feed_dict={self.block_to_comp: i})\n",
        "            print('Block {} of {} compressed'.format(i, n_blocks))\n",
        "            for j in range(retrain_iter):\n",
        "                self.training_step(training='compression', extra_ops=self.kl_penalty_update)\n",
        "\n",
        "        mean_validation_acc = 0.0\n",
        "        for i in range(100):\n",
        "            validation_acc = self.sess.run(self.accuracy,\n",
        "                                           feed_dict=self.get_feed_dict(validation=True))\n",
        "            mean_validation_acc += validation_acc\n",
        "        return mean_validation_acc / 100.\n",
        "\n",
        "    def initialize_variables(self,\n",
        "                             dimensions,\n",
        "                             initializers,\n",
        "                             hash_group_sizes,\n",
        "                             block_size,\n",
        "                             bits_per_block,\n",
        "                             weight_decay=5e-4,\n",
        "                             kl_penalty_step=1.00005):\n",
        "        assert len(initializers) == len(dimensions)\n",
        "        num_vars = 0\n",
        "        for dim, group_size in zip(dimensions, hash_group_sizes):\n",
        "            assert np.prod(dim) % group_size == 0\n",
        "            num_vars += np.prod(dim) / group_size\n",
        "        n_blocks = np.int64(1 + (num_vars - 1) / block_size)\n",
        "        shape = [n_blocks, block_size]\n",
        "        print('Number of blocks: {}, Block size: {}, Bits per block: {}, Target KL: {}, Overall bits {}, Ratio: {}'.format(\n",
        "            n_blocks, block_size, bits_per_block, bits_per_block, bits_per_block*n_blocks, np.sum([np.prod(dim) for dim in dimensions])*32. / (bits_per_block * n_blocks)\n",
        "        ))\n",
        "        num_vars_ub = np.prod(shape)\n",
        "\n",
        "        np.random.seed(420)\n",
        "        num_vars_ub = np.int64(num_vars_ub)\n",
        "        num_vars = np.int64(num_vars)\n",
        "        permutation = np.random.permutation(num_vars_ub)\n",
        "        permutation_inv = np.argsort(permutation)\n",
        "        var_sizes = [np.prod(dim)/group_size for dim, group_size in zip(dimensions, hash_group_sizes)]\n",
        "        var_sizes = np.int64(var_sizes)\n",
        "\n",
        "        self.p_scale_vars = tf.Variable(tf.fill([len(dimensions) + 1], -2.), dtype=DTYPE)\n",
        "        print(range(len(dimensions) + 1))\n",
        "        #p_perm_inv = np.repeat(range(len(dimensions) + 1), var_sizes + [num_vars_ub - num_vars])[permutation_inv]\n",
        "        p_perm_inv = np.repeat(range(len(dimensions)), var_sizes + [num_vars_ub - num_vars])[permutation_inv]\n",
        "        #self.p_scale = tf.reshape(tf.gather(tf.exp(self.p_scale_vars), p_perm_inv), (shape))\n",
        "        shape = np.int64(shape)\n",
        "        self.p_scale = tf.reshape(tf.gather(tf.exp(self.p_scale_vars), p_perm_inv), (shape))\n",
        "        p = tf.contrib.distributions.Normal(loc=0., scale=self.p_scale)\n",
        "        mu_init_list = []\n",
        "        for (type, val), size in zip(initializers, var_sizes):\n",
        "            if type == 'normal':\n",
        "                mu_init_list.append(np.random.normal(size=size, loc=0., scale=val))\n",
        "            elif type == 'uni':\n",
        "                mu_init_list.append(np.random.uniform(-val, val, size=size))\n",
        "            elif type == 'zero':\n",
        "                mu_init_list.append(np.zeros(size))\n",
        "            else:\n",
        "                assert False\n",
        "\n",
        "        mu_init = np.concatenate(mu_init_list)\n",
        "        # print(num_vars, mu_init.shape)\n",
        "        # print(var_sizes, [init.shape for init in mu_init_list])\n",
        "        init_inv_permuted = np.concatenate((mu_init,\n",
        "                                            np.zeros(num_vars_ub - num_vars)),\n",
        "                                           axis=0)[permutation_inv]\n",
        "\n",
        "        mu = tf.Variable(init_inv_permuted.reshape(shape), dtype=DTYPE, name='mu')\n",
        "        self.mu = mu\n",
        "        self.weight_decay_loss = tf.reduce_sum(tf.square(mu)) * weight_decay\n",
        "        self.sigma_var = tf.Variable(tf.fill(shape, tf.cast(-10., dtype=DTYPE, name='sigma')))\n",
        "        sigma = tf.exp(self.sigma_var)\n",
        "        self.sigma = sigma\n",
        "        epsilon = tf.random_normal(shape)\n",
        "        self.w_dist = tf.contrib.distributions.Normal(loc=mu, scale=sigma)\n",
        "        variational_weights = mu + epsilon * sigma\n",
        "        self.fixed_weights = tf.Variable(tf.zeros_like(variational_weights), trainable=False)\n",
        "        self.mask = tf.Variable(tf.ones([n_blocks]), trainable=False)\n",
        "        kl_penalties = tf.Variable(tf.fill([n_blocks], tf.cast(1e-8, dtype=DTYPE)), trainable=False)\n",
        "        self.kl_penalties = kl_penalties\n",
        "\n",
        "        kl_target = tf.Variable(bits_per_block * np.log(2.), dtype=tf.float32, trainable=False)\n",
        "        block_kl = tf.reduce_sum(tf.distributions.kl_divergence(self.w_dist, p), axis=1)\n",
        "        self.mean_kl = tf.reduce_mean(block_kl)\n",
        "\n",
        "        self.enable_kl_loss = tf.Variable(1., dtype=DTYPE, trainable=False)\n",
        "        self.kl_loss = tf.reduce_sum(block_kl * self.mask * kl_penalties) * self.enable_kl_loss\n",
        "        self.kl_penalty_step = tf.Variable(kl_penalty_step, trainable=False)\n",
        "        self.kl_penalty_update = [kl_penalties.assign(tf.where(tf.logical_and(tf.cast(self.mask, tf.bool),\n",
        "                                                                              tf.greater(block_kl, kl_target)),\n",
        "                                                               kl_penalties * self.kl_penalty_step,\n",
        "                                                               kl_penalties / self.kl_penalty_step))]\n",
        "        mask_expanded = tf.expand_dims(self.mask, 1)\n",
        "        combined_weights = tf.reshape(mask_expanded * variational_weights\n",
        "                                      + (1. - mask_expanded) * self.fixed_weights,\n",
        "                                      [-1])\n",
        "\n",
        "        permuted_weights = tf.gather(combined_weights, permutation)\n",
        "        split_weights = tf.split(permuted_weights, var_sizes + [num_vars_ub - num_vars])\n",
        "        result = []\n",
        "        i = 0\n",
        "        for dim in dimensions:\n",
        "            split = tf.expand_dims(split_weights[i], axis=1) * np.random.choice([-1., 1.], size=hash_group_sizes[i])\n",
        "            # print(split.get_shape().as_list())\n",
        "            result.append(tf.reshape(split, dim))\n",
        "            i += 1\n",
        "        self.initialize_compressor(bits_per_block)\n",
        "        return result\n",
        "\n",
        "    def initialize_compressor(self, bits_per_block):\n",
        "        with tf.variable_scope('compressor'):\n",
        "            self.block_to_comp = tf.placeholder(tf.int32)\n",
        "            shape = self.fixed_weights.get_shape().as_list()\n",
        "            n_blocks = shape[0]\n",
        "            sobol_dim = shape[1]\n",
        "            assert sobol_dim <= 40\n",
        "            uni_quasi = np.array(sobol_seq.i4_sobol_generate(sobol_dim, np.power(2, bits_per_block), skip=1)).transpose()\n",
        "            normal_quasi = norm.ppf(uni_quasi).transpose()\n",
        "            sample_block = tf.constant(normal_quasi, dtype=DTYPE)\n",
        "            block_p = self.p_scale[self.block_to_comp, :]\n",
        "            block_mu = self.mu[self.block_to_comp, :]\n",
        "            block_sigma = self.sigma[self.block_to_comp, :]\n",
        "            nll_q = tf.reduce_sum(tf.square(block_mu - sample_block * block_p) / (2*tf.square(block_sigma)), axis=1)\n",
        "            nll_p = tf.reduce_sum(tf.square(sample_block), axis=1)\n",
        "            dist = tf.distributions.Categorical(probs=tf.nn.softmax(nll_p - nll_q))\n",
        "            index = dist.sample([])\n",
        "            best_sample = sample_block[index, :] * block_p\n",
        "            self.comp_ops = []\n",
        "            self.comp_ops.append(tf.scatter_update(self.fixed_weights,\n",
        "                                                   [self.block_to_comp],\n",
        "                                                   [best_sample]))\n",
        "            self.comp_ops.append(tf.scatter_update(self.mask, [self.block_to_comp], [0.]))\n",
        "\n",
        "    def initialize_session(self, load_name=None):\n",
        "        # Инициализация переменных\n",
        "        self.saver = tf.train.Saver(max_to_keep=None)\n",
        "        self.loader = tf.train.Saver(var_list=[v for v in tf.all_variables() if v not in []])\n",
        "        init = tf.global_variables_initializer()\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        self.sess = tf.Session(config=config)\n",
        "\n",
        "        # Run the initializer\n",
        "        self.sess.run(init)\n",
        "\n",
        "        if load_name is not None:\n",
        "            # tf.reset_default_graph()\n",
        "            path = '/scratch/mh740/compression_models/{}'.format(load_name)\n",
        "            self.loader.restore(self.sess, path)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qHBMueUDD_z"
      },
      "source": [
        "########################################################################\n",
        "#\n",
        "# Functions for downloading and extracting data-files from the internet.\n",
        "#\n",
        "# Implemented in Python 3.5\n",
        "#\n",
        "########################################################################\n",
        "#\n",
        "# This code is part of the TensorFlow Tutorials available at:\n",
        "#\n",
        "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
        "#\n",
        "# Published under the MIT License. See the file LICENSE for details.\n",
        "#\n",
        "# Copyright 2016 by Magnus Erik Hvass Pedersen\n",
        "#\n",
        "########################################################################\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import urllib\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "########################################################################\n",
        "\n",
        "\n",
        "def _print_download_progress(count, block_size, total_size):\n",
        "    \"\"\"\n",
        "    Function used for printing the download progress.\n",
        "    Used as a call-back function in maybe_download_and_extract().\n",
        "    \"\"\"\n",
        "\n",
        "    # Percentage completion.\n",
        "    pct_complete = float(count * block_size) / total_size\n",
        "\n",
        "    # Limit it because rounding errors may cause it to exceed 100%.\n",
        "    pct_complete = min(1.0, pct_complete)\n",
        "\n",
        "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
        "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
        "\n",
        "    # Print it.\n",
        "    sys.stdout.write(msg)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "def download(base_url, filename, download_dir):\n",
        "    \"\"\"\n",
        "    Download the given file if it does not already exist in the download_dir.\n",
        "    :param base_url: The internet URL without the filename.\n",
        "    :param filename: The filename that will be added to the base_url.\n",
        "    :param download_dir: Local directory for storing the file.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Path for local file.\n",
        "    save_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists, otherwise we need to download it now.\n",
        "    if not os.path.exists(save_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        print(\"Downloading\", filename, \"...\")\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        url = base_url + filename\n",
        "        file_path, _ = urllib.urlretrieve(url=url,\n",
        "                                          filename=save_path,\n",
        "                                          reporthook=_print_download_progress)\n",
        "\n",
        "        print(\" Done!\")\n",
        "\n",
        "\n",
        "def maybe_download_and_extract(url, download_dir):\n",
        "    \"\"\"\n",
        "    Download and extract the data if it doesn't already exist.\n",
        "    Assumes the url is a tar-ball file.\n",
        "    :param url:\n",
        "        Internet URL for the tar-file to download.\n",
        "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    :param download_dir:\n",
        "        Directory where the downloaded file is saved.\n",
        "        Example: \"data/CIFAR-10/\"\n",
        "    :return:\n",
        "        Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filename for saving the file downloaded from the internet.\n",
        "    # Use the filename from the URL and add it to the download_dir.\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists.\n",
        "    # If it exists then we assume it has also been extracted,\n",
        "    # otherwise we need to download and extract it now.\n",
        "    if not os.path.exists(file_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        file_path, _ = urllib.urlretrieve(url=url,\n",
        "                                          filename=file_path,\n",
        "                                          reporthook=_print_download_progress)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            # Unpack the zip-file.\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            # Unpack the tar-ball.\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5LMUyBJDbs2",
        "outputId": "345666a2-b1ba-47bd-cb0d-e8b85b2eabbd"
      },
      "source": [
        "print(tf.__version__) #must be 1.15.5!"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p68uQ4pDRpu"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "class Lenet5(Compressible):\n",
        "    def conv2d(self, x, W, b, padding='SAME', strides=1):\n",
        "        x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=padding)\n",
        "        x = tf.nn.bias_add(x, b)\n",
        "        return tf.nn.relu(x)\n",
        "\n",
        "    def maxpool2d(self, x, k=2, padding='SAME'):\n",
        "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                              padding=padding)\n",
        "\n",
        "    # Создаем модель\n",
        "    def conv_net(self, x, weights):\n",
        "        # MNIST подается на вход как вектор (1, 784)\n",
        "        # Делаем RESHAPE для соответствия формату изображения [Height, Width, Channel]\n",
        "        # Входной тензор становится следующим: [Batch Size, Height, Width, Channel]\n",
        "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "        # Сверточный слой\n",
        "        conv1 = self.conv2d(x, weights['wc1'], weights['bc1'], padding='VALID')\n",
        "        print(conv1.shape)\n",
        "        # Maxpool\n",
        "        conv1 = self.maxpool2d(conv1, k=2, padding='SAME')\n",
        "        print(conv1.shape)\n",
        "        # Сверточный слой\n",
        "        conv2 = self.conv2d(conv1, weights['wc2'], weights['bc2'], padding='VALID')\n",
        "        print(conv2.shape)\n",
        "        # Maxpool\n",
        "        conv2 = self.maxpool2d(conv2, k=2, padding='SAME')\n",
        "        print(conv2.shape)\n",
        "\n",
        "        # Полносвязный слой\n",
        "        # Изменение выхода conv2, чтобы соответствовать входу полносвязаного\n",
        "        fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), weights['bd1'])\n",
        "        fc1 = tf.nn.relu(fc1)\n",
        "\n",
        "        # Выход, предсказание класса\n",
        "        out = tf.add(tf.matmul(fc1, weights['out']), weights['bout'])\n",
        "        return out\n",
        "\n",
        "    def __init__(self, bpb, load_name=None):\n",
        "        super(Lenet5, self).__init__('Lenet5')\n",
        "        self.mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "        # Обучающие параметры\n",
        "        self.batch_size = 256\n",
        "\n",
        "        # Параметры сети\n",
        "        num_input = 784  # MNIST data input (img shape: 28*28)\n",
        "        num_classes = 10  # MNIST total classes (0-9 digits)\n",
        "\n",
        "        self.X = tf.placeholder(tf.float32, [None, num_input]) - 0.5\n",
        "        self.Y = tf.placeholder(tf.float32, [None, num_classes])\n",
        "\n",
        "        # Веса\n",
        "        weight_names = ['wc1', 'wc2', 'wd1', 'out', 'bc1', 'bc2', 'bd1', 'bout']\n",
        "        weight_dims = [[5, 5, 1, 20], [5, 5, 20, 50], [4 * 4 * 50, 500],\n",
        "                       [500, num_classes], [20], [50], [500], [num_classes]]\n",
        "        weight_hash_groups = [1, 2, 50, 1, 1, 1, 1, 1]\n",
        "        weight_initializers = []\n",
        "        for d in weight_dims:\n",
        "            if len(d) == 4:\n",
        "                weight_initializers.append(('normal', np.sqrt(1. / (d[0] * d[1] * d[2]))))\n",
        "            else:\n",
        "                weight_initializers.append(('normal', np.sqrt(1. / d[0])))\n",
        "\n",
        "        weights = {}\n",
        "        weights.update(zip(weight_names, self.initialize_variables(weight_dims,\n",
        "                                                                   weight_initializers,\n",
        "                                                                   weight_hash_groups,\n",
        "                                                                   30, bpb,\n",
        "                                                                   kl_penalty_step=1.0001)))\n",
        "        # Строим модель\n",
        "        logits = self.conv_net(self.X, weights)\n",
        "\n",
        "        # Оцениваем модель\n",
        "        prediction = tf.nn.softmax(logits)\n",
        "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, DTYPE))\n",
        "\n",
        "        # Определяем loss и оптимизатор\n",
        "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=self.Y)) + self.kl_loss\n",
        "\n",
        "        global_step = tf.Variable(initial_value=0,\n",
        "                                  name='global_step', trainable=False)\n",
        "        learning_rate = tf.train.exponential_decay(\n",
        "            0.001,  # Базовый learning rate.\n",
        "            global_step,  # Текущий индекс в датасете\n",
        "            30 * self.mnist.train.images.shape[0] / self.batch_size,  # Шаг\n",
        "            1.,  # Скорость\n",
        "            staircase=True)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "        self.train_op = optimizer.minimize(self.loss)\n",
        "        no_scales_list = [v for v in tf.trainable_variables() if v is not self.p_scale_vars]\n",
        "        assert len(no_scales_list) < len(tf.trainable_variables())\n",
        "        self.train_op_no_scales = optimizer.minimize(self.loss, var_list=no_scales_list)\n",
        "\n",
        "        self.initialize_session(load_name)\n",
        "\n",
        "    def get_feed_dict(self, validation=False):\n",
        "        if validation:\n",
        "            batch_x, batch_y = self.mnist.validation.images, self.mnist.validation.labels\n",
        "        else:\n",
        "            batch_x, batch_y = self.mnist.train.next_batch(self.batch_size)\n",
        "        return {self.X: batch_x, self.Y: batch_y}\n",
        "\n",
        "    def get_train_op(self, training=True):\n",
        "        if training:\n",
        "            return self.train_op\n",
        "        else:\n",
        "            return self.train_op_no_scales"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFhf_bh7DWDc",
        "outputId": "3da0f0b3-22f6-4da0-e803-be41de9cdfc4"
      },
      "source": [
        "# Обучаем LeNet-5 на MNIST\n",
        "model = Lenet5(bpb=10)\n",
        "\n",
        "model.train(200, False)\n",
        "model.train(200, True)\n",
        "# переобучаем,\n",
        "print(model.compress(100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-743628eb5eec>:44: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Number of blocks: 886, Block size: 30, Bits per block: 10, Target KL: 10, Overall bits 8860, Ratio: 1556.9480812641084\n",
            "range(0, 9)\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-e52d2293dc42>:122: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-1-e52d2293dc42>:156: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-1-e52d2293dc42>:165: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-1-e52d2293dc42>:198: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/distributions/categorical.py:278: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "(?, 24, 24, 20)\n",
            "(?, 12, 12, 20)\n",
            "(?, 8, 8, 50)\n",
            "(?, 4, 4, 50)\n",
            "WARNING:tensorflow:From <ipython-input-4-743628eb5eec>:84: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-e52d2293dc42>:210: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "Iteration 1, Validation score = 0.0989999994635582, Training score = 0.1015625, Loss = 2.4400851726531982, KL-Loss = 0.0, KL_2 = 327.7253624940578\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/pretrain/1.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 0 of 886 compressed\n",
            "Block 1 of 886 compressed\n",
            "Block 2 of 886 compressed\n",
            "Block 3 of 886 compressed\n",
            "Block 4 of 886 compressed\n",
            "Block 5 of 886 compressed\n",
            "Iteration 1000, Validation score = 0.9876200258731842, Training score = 0.9921875, Loss = 0.02867722511291504, KL-Loss = 0.0025714850053191185, KL_2 = 306.2968415203656\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/1000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 6 of 886 compressed\n",
            "Block 7 of 886 compressed\n",
            "Block 8 of 886 compressed\n",
            "Block 9 of 886 compressed\n",
            "Block 10 of 886 compressed\n",
            "Block 11 of 886 compressed\n",
            "Block 12 of 886 compressed\n",
            "Block 13 of 886 compressed\n",
            "Block 14 of 886 compressed\n",
            "Block 15 of 886 compressed\n",
            "Iteration 2000, Validation score = 0.9895200133323669, Training score = 0.98828125, Loss = 0.041620995849370956, KL-Loss = 0.004193314351141453, KL_2 = 306.48904382752505\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/2000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 16 of 886 compressed\n",
            "Block 17 of 886 compressed\n",
            "Block 18 of 886 compressed\n",
            "Block 19 of 886 compressed\n",
            "Block 20 of 886 compressed\n",
            "Block 21 of 886 compressed\n",
            "Block 22 of 886 compressed\n",
            "Block 23 of 886 compressed\n",
            "Block 24 of 886 compressed\n",
            "Block 25 of 886 compressed\n",
            "Iteration 3000, Validation score = 0.9919999837875366, Training score = 0.99609375, Loss = 0.016412725672125816, KL-Loss = 0.006730012129992247, KL_2 = 301.99143059038846\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/3000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 26 of 886 compressed\n",
            "Block 27 of 886 compressed\n",
            "Block 28 of 886 compressed\n",
            "Block 29 of 886 compressed\n",
            "Block 30 of 886 compressed\n",
            "Block 31 of 886 compressed\n",
            "Block 32 of 886 compressed\n",
            "Block 33 of 886 compressed\n",
            "Block 34 of 886 compressed\n",
            "Block 35 of 886 compressed\n",
            "Iteration 4000, Validation score = 0.991599977016449, Training score = 1.0, Loss = 0.013912144117057323, KL-Loss = 0.010619157925248146, KL_2 = 292.8432523774664\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/4000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 36 of 886 compressed\n",
            "Block 37 of 886 compressed\n",
            "Block 38 of 886 compressed\n",
            "Block 39 of 886 compressed\n",
            "Block 40 of 886 compressed\n",
            "Block 41 of 886 compressed\n",
            "Block 42 of 886 compressed\n",
            "Block 43 of 886 compressed\n",
            "Block 44 of 886 compressed\n",
            "Block 45 of 886 compressed\n",
            "Iteration 5000, Validation score = 0.9914000034332275, Training score = 1.0, Loss = 0.017149057239294052, KL-Loss = 0.016364993527531624, KL_2 = 277.8422266317191\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/5000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 46 of 886 compressed\n",
            "Block 47 of 886 compressed\n",
            "Block 48 of 886 compressed\n",
            "Block 49 of 886 compressed\n",
            "Block 50 of 886 compressed\n",
            "Block 51 of 886 compressed\n",
            "Block 52 of 886 compressed\n",
            "Block 53 of 886 compressed\n",
            "Block 54 of 886 compressed\n",
            "Block 55 of 886 compressed\n",
            "Iteration 6000, Validation score = 0.9887800097465516, Training score = 0.99609375, Loss = 0.03463714197278023, KL-Loss = 0.024832425639033318, KL_2 = 260.06339214368404\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/6000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 56 of 886 compressed\n",
            "Block 57 of 886 compressed\n",
            "Block 58 of 886 compressed\n",
            "Block 59 of 886 compressed\n",
            "Block 60 of 886 compressed\n",
            "Block 61 of 886 compressed\n",
            "Block 62 of 886 compressed\n",
            "Block 63 of 886 compressed\n",
            "Block 64 of 886 compressed\n",
            "Block 65 of 886 compressed\n",
            "Iteration 7000, Validation score = 0.9899800062179566, Training score = 1.0, Loss = 0.04374230280518532, KL-Loss = 0.03688172996044159, KL_2 = 239.07895514002135\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/7000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 66 of 886 compressed\n",
            "Block 67 of 886 compressed\n",
            "Block 68 of 886 compressed\n",
            "Block 69 of 886 compressed\n",
            "Block 70 of 886 compressed\n",
            "Block 71 of 886 compressed\n",
            "Block 72 of 886 compressed\n",
            "Block 73 of 886 compressed\n",
            "Block 74 of 886 compressed\n",
            "Block 75 of 886 compressed\n",
            "Iteration 8000, Validation score = 0.9914999961853027, Training score = 1.0, Loss = 0.05393083021044731, KL-Loss = 0.05371623486280441, KL_2 = 220.74447084841145\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/8000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 76 of 886 compressed\n",
            "Block 77 of 886 compressed\n",
            "Block 78 of 886 compressed\n",
            "Block 79 of 886 compressed\n",
            "Block 80 of 886 compressed\n",
            "Block 81 of 886 compressed\n",
            "Block 82 of 886 compressed\n",
            "Block 83 of 886 compressed\n",
            "Block 84 of 886 compressed\n",
            "Block 85 of 886 compressed\n",
            "Iteration 9000, Validation score = 0.9910199999809265, Training score = 1.0, Loss = 0.082838274538517, KL-Loss = 0.07735944539308548, KL_2 = 198.07320599130705\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/9000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 86 of 886 compressed\n",
            "Block 87 of 886 compressed\n",
            "Block 88 of 886 compressed\n",
            "Block 89 of 886 compressed\n",
            "Block 90 of 886 compressed\n",
            "Block 91 of 886 compressed\n",
            "Block 92 of 886 compressed\n",
            "Block 93 of 886 compressed\n",
            "Block 94 of 886 compressed\n",
            "Block 95 of 886 compressed\n",
            "Iteration 10000, Validation score = 0.9920600056648254, Training score = 1.0, Loss = 0.10586869716644287, KL-Loss = 0.10582220554351807, KL_2 = 171.87248290424955\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/10000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 96 of 886 compressed\n",
            "Block 97 of 886 compressed\n",
            "Block 98 of 886 compressed\n",
            "Block 99 of 886 compressed\n",
            "Block 100 of 886 compressed\n",
            "Block 101 of 886 compressed\n",
            "Block 102 of 886 compressed\n",
            "Block 103 of 886 compressed\n",
            "Block 104 of 886 compressed\n",
            "Block 105 of 886 compressed\n",
            "Iteration 11000, Validation score = 0.9888200044631958, Training score = 0.99609375, Loss = 0.15726453065872192, KL-Loss = 0.13187435269355774, KL_2 = 138.33695566807774\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/11000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 106 of 886 compressed\n",
            "Block 107 of 886 compressed\n",
            "Block 108 of 886 compressed\n",
            "Block 109 of 886 compressed\n",
            "Block 110 of 886 compressed\n",
            "Block 111 of 886 compressed\n",
            "Block 112 of 886 compressed\n",
            "Block 113 of 886 compressed\n",
            "Block 114 of 886 compressed\n",
            "Block 115 of 886 compressed\n",
            "Iteration 12000, Validation score = 0.9896200001239777, Training score = 0.9921875, Loss = 0.18922054767608643, KL-Loss = 0.16245752573013306, KL_2 = 113.14725942341077\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/12000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 116 of 886 compressed\n",
            "Block 117 of 886 compressed\n",
            "Block 118 of 886 compressed\n",
            "Block 119 of 886 compressed\n",
            "Block 120 of 886 compressed\n",
            "Block 121 of 886 compressed\n",
            "Block 122 of 886 compressed\n",
            "Block 123 of 886 compressed\n",
            "Block 124 of 886 compressed\n",
            "Block 125 of 886 compressed\n",
            "Iteration 13000, Validation score = 0.9898400008678436, Training score = 0.99609375, Loss = 0.19691839814186096, KL-Loss = 0.18181836605072021, KL_2 = 90.93865816607388\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/13000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 126 of 886 compressed\n",
            "Block 127 of 886 compressed\n",
            "Block 128 of 886 compressed\n",
            "Block 129 of 886 compressed\n",
            "Block 130 of 886 compressed\n",
            "Block 131 of 886 compressed\n",
            "Block 132 of 886 compressed\n",
            "Block 133 of 886 compressed\n",
            "Block 134 of 886 compressed\n",
            "Block 135 of 886 compressed\n",
            "Iteration 14000, Validation score = 0.9867999970912933, Training score = 0.984375, Loss = 0.22012481093406677, KL-Loss = 0.18113280832767487, KL_2 = 77.91372683735234\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/14000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 136 of 886 compressed\n",
            "Block 137 of 886 compressed\n",
            "Block 138 of 886 compressed\n",
            "Block 139 of 886 compressed\n",
            "Block 140 of 886 compressed\n",
            "Block 141 of 886 compressed\n",
            "Block 142 of 886 compressed\n",
            "Block 143 of 886 compressed\n",
            "Block 144 of 886 compressed\n",
            "Block 145 of 886 compressed\n",
            "Iteration 15000, Validation score = 0.9848600029945374, Training score = 0.99609375, Loss = 0.22948259115219116, KL-Loss = 0.19260838627815247, KL_2 = 71.39638787259672\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/15000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 146 of 886 compressed\n",
            "Block 147 of 886 compressed\n",
            "Block 148 of 886 compressed\n",
            "Block 149 of 886 compressed\n",
            "Block 150 of 886 compressed\n",
            "Block 151 of 886 compressed\n",
            "Block 152 of 886 compressed\n",
            "Block 153 of 886 compressed\n",
            "Block 154 of 886 compressed\n",
            "Block 155 of 886 compressed\n",
            "Iteration 16000, Validation score = 0.9808999955654144, Training score = 0.96875, Loss = 0.32913386821746826, KL-Loss = 0.22113065421581268, KL_2 = 66.38924920298552\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/16000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 156 of 886 compressed\n",
            "Block 157 of 886 compressed\n",
            "Block 158 of 886 compressed\n",
            "Block 159 of 886 compressed\n",
            "Block 160 of 886 compressed\n",
            "Block 161 of 886 compressed\n",
            "Block 162 of 886 compressed\n",
            "Block 163 of 886 compressed\n",
            "Block 164 of 886 compressed\n",
            "Block 165 of 886 compressed\n",
            "Iteration 17000, Validation score = 0.9698400139808655, Training score = 0.96875, Loss = 0.3463808298110962, KL-Loss = 0.24912771582603455, KL_2 = 62.129604920194794\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/17000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 166 of 886 compressed\n",
            "Block 167 of 886 compressed\n",
            "Block 168 of 886 compressed\n",
            "Block 169 of 886 compressed\n",
            "Block 170 of 886 compressed\n",
            "Block 171 of 886 compressed\n",
            "Block 172 of 886 compressed\n",
            "Block 173 of 886 compressed\n",
            "Block 174 of 886 compressed\n",
            "Block 175 of 886 compressed\n",
            "Iteration 18000, Validation score = 0.9742800116539001, Training score = 0.97265625, Loss = 0.3290341794490814, KL-Loss = 0.26942822337150574, KL_2 = 58.756862785152705\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/18000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 176 of 886 compressed\n",
            "Block 177 of 886 compressed\n",
            "Block 178 of 886 compressed\n",
            "Block 179 of 886 compressed\n",
            "Block 180 of 886 compressed\n",
            "Block 181 of 886 compressed\n",
            "Block 182 of 886 compressed\n",
            "Block 183 of 886 compressed\n",
            "Block 184 of 886 compressed\n",
            "Block 185 of 886 compressed\n",
            "Iteration 19000, Validation score = 0.9728200078010559, Training score = 0.984375, Loss = 0.3219054341316223, KL-Loss = 0.25512346625328064, KL_2 = 56.1220940773793\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/19000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 186 of 886 compressed\n",
            "Block 187 of 886 compressed\n",
            "Block 188 of 886 compressed\n",
            "Block 189 of 886 compressed\n",
            "Block 190 of 886 compressed\n",
            "Block 191 of 886 compressed\n",
            "Block 192 of 886 compressed\n",
            "Block 193 of 886 compressed\n",
            "Block 194 of 886 compressed\n",
            "Block 195 of 886 compressed\n",
            "Iteration 20000, Validation score = 0.9747999966144562, Training score = 0.97265625, Loss = 0.25110170245170593, KL-Loss = 0.19966654479503632, KL_2 = 54.02457165367718\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/20000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 196 of 886 compressed\n",
            "Block 197 of 886 compressed\n",
            "Block 198 of 886 compressed\n",
            "Block 199 of 886 compressed\n",
            "Block 200 of 886 compressed\n",
            "Block 201 of 886 compressed\n",
            "Block 202 of 886 compressed\n",
            "Block 203 of 886 compressed\n",
            "Block 204 of 886 compressed\n",
            "Block 205 of 886 compressed\n",
            "Iteration 21000, Validation score = 0.975659990310669, Training score = 0.96484375, Loss = 0.2808399200439453, KL-Loss = 0.16757529973983765, KL_2 = 52.34988439952515\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/21000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 206 of 886 compressed\n",
            "Block 207 of 886 compressed\n",
            "Block 208 of 886 compressed\n",
            "Block 209 of 886 compressed\n",
            "Block 210 of 886 compressed\n",
            "Block 211 of 886 compressed\n",
            "Block 212 of 886 compressed\n",
            "Block 213 of 886 compressed\n",
            "Block 214 of 886 compressed\n",
            "Block 215 of 886 compressed\n",
            "Iteration 22000, Validation score = 0.9771200001239777, Training score = 0.9765625, Loss = 0.22445213794708252, KL-Loss = 0.1528438776731491, KL_2 = 51.123766422937116\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/22000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 216 of 886 compressed\n",
            "Block 217 of 886 compressed\n",
            "Block 218 of 886 compressed\n",
            "Block 219 of 886 compressed\n",
            "Block 220 of 886 compressed\n",
            "Block 221 of 886 compressed\n",
            "Block 222 of 886 compressed\n",
            "Block 223 of 886 compressed\n",
            "Block 224 of 886 compressed\n",
            "Block 225 of 886 compressed\n",
            "Iteration 23000, Validation score = 0.9770399987697601, Training score = 0.9609375, Loss = 0.23765486478805542, KL-Loss = 0.13753364980220795, KL_2 = 50.096438376967185\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/23000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 226 of 886 compressed\n",
            "Block 227 of 886 compressed\n",
            "Block 228 of 886 compressed\n",
            "Block 229 of 886 compressed\n",
            "Block 230 of 886 compressed\n",
            "Block 231 of 886 compressed\n",
            "Block 232 of 886 compressed\n",
            "Block 233 of 886 compressed\n",
            "Block 234 of 886 compressed\n",
            "Block 235 of 886 compressed\n",
            "Iteration 24000, Validation score = 0.9782000064849854, Training score = 0.97265625, Loss = 0.19840331375598907, KL-Loss = 0.1308334767818451, KL_2 = 49.260536652436\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/24000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 236 of 886 compressed\n",
            "Block 237 of 886 compressed\n",
            "Block 238 of 886 compressed\n",
            "Block 239 of 886 compressed\n",
            "Block 240 of 886 compressed\n",
            "Block 241 of 886 compressed\n",
            "Block 242 of 886 compressed\n",
            "Block 243 of 886 compressed\n",
            "Block 244 of 886 compressed\n",
            "Block 245 of 886 compressed\n",
            "Iteration 25000, Validation score = 0.978220009803772, Training score = 0.98046875, Loss = 0.18299877643585205, KL-Loss = 0.12458118051290512, KL_2 = 48.62341935507809\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/25000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 246 of 886 compressed\n",
            "Block 247 of 886 compressed\n",
            "Block 248 of 886 compressed\n",
            "Block 249 of 886 compressed\n",
            "Block 250 of 886 compressed\n",
            "Block 251 of 886 compressed\n",
            "Block 252 of 886 compressed\n",
            "Block 253 of 886 compressed\n",
            "Block 254 of 886 compressed\n",
            "Block 255 of 886 compressed\n",
            "Iteration 26000, Validation score = 0.9777599990367889, Training score = 0.97265625, Loss = 0.19999977946281433, KL-Loss = 0.11737241595983505, KL_2 = 48.01942178869273\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/26000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 256 of 886 compressed\n",
            "Block 257 of 886 compressed\n",
            "Block 258 of 886 compressed\n",
            "Block 259 of 886 compressed\n",
            "Block 260 of 886 compressed\n",
            "Block 261 of 886 compressed\n",
            "Block 262 of 886 compressed\n",
            "Block 263 of 886 compressed\n",
            "Block 264 of 886 compressed\n",
            "Block 265 of 886 compressed\n",
            "Iteration 27000, Validation score = 0.9791400074958801, Training score = 0.97265625, Loss = 0.21290919184684753, KL-Loss = 0.1152537390589714, KL_2 = 47.557732298659715\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/27000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 266 of 886 compressed\n",
            "Block 267 of 886 compressed\n",
            "Block 268 of 886 compressed\n",
            "Block 269 of 886 compressed\n",
            "Block 270 of 886 compressed\n",
            "Block 271 of 886 compressed\n",
            "Block 272 of 886 compressed\n",
            "Block 273 of 886 compressed\n",
            "Block 274 of 886 compressed\n",
            "Block 275 of 886 compressed\n",
            "Iteration 28000, Validation score = 0.9779999911785126, Training score = 0.984375, Loss = 0.17867912352085114, KL-Loss = 0.1114729568362236, KL_2 = 47.10887684196468\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/28000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 276 of 886 compressed\n",
            "Block 277 of 886 compressed\n",
            "Block 278 of 886 compressed\n",
            "Block 279 of 886 compressed\n",
            "Block 280 of 886 compressed\n",
            "Block 281 of 886 compressed\n",
            "Block 282 of 886 compressed\n",
            "Block 283 of 886 compressed\n",
            "Block 284 of 886 compressed\n",
            "Block 285 of 886 compressed\n",
            "Iteration 29000, Validation score = 0.9761600017547607, Training score = 0.9765625, Loss = 0.1592325121164322, KL-Loss = 0.10799328237771988, KL_2 = 46.774586596245996\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/29000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 286 of 886 compressed\n",
            "Block 287 of 886 compressed\n",
            "Block 288 of 886 compressed\n",
            "Block 289 of 886 compressed\n",
            "Block 290 of 886 compressed\n",
            "Block 291 of 886 compressed\n",
            "Block 292 of 886 compressed\n",
            "Block 293 of 886 compressed\n",
            "Block 294 of 886 compressed\n",
            "Block 295 of 886 compressed\n",
            "Iteration 30000, Validation score = 0.9801999926567078, Training score = 0.984375, Loss = 0.15404930710792542, KL-Loss = 0.10319748520851135, KL_2 = 46.48273891703785\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/30000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 296 of 886 compressed\n",
            "Block 297 of 886 compressed\n",
            "Block 298 of 886 compressed\n",
            "Block 299 of 886 compressed\n",
            "Block 300 of 886 compressed\n",
            "Block 301 of 886 compressed\n",
            "Block 302 of 886 compressed\n",
            "Block 303 of 886 compressed\n",
            "Block 304 of 886 compressed\n",
            "Block 305 of 886 compressed\n",
            "Iteration 31000, Validation score = 0.9785599946975708, Training score = 0.98828125, Loss = 0.15030986070632935, KL-Loss = 0.10088330507278442, KL_2 = 46.14469257022432\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/31000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 306 of 886 compressed\n",
            "Block 307 of 886 compressed\n",
            "Block 308 of 886 compressed\n",
            "Block 309 of 886 compressed\n",
            "Block 310 of 886 compressed\n",
            "Block 311 of 886 compressed\n",
            "Block 312 of 886 compressed\n",
            "Block 313 of 886 compressed\n",
            "Block 314 of 886 compressed\n",
            "Block 315 of 886 compressed\n",
            "Iteration 32000, Validation score = 0.9794600069522857, Training score = 0.97265625, Loss = 0.17898866534233093, KL-Loss = 0.09702540934085846, KL_2 = 45.96064086485457\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/32000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 316 of 886 compressed\n",
            "Block 317 of 886 compressed\n",
            "Block 318 of 886 compressed\n",
            "Block 319 of 886 compressed\n",
            "Block 320 of 886 compressed\n",
            "Block 321 of 886 compressed\n",
            "Block 322 of 886 compressed\n",
            "Block 323 of 886 compressed\n",
            "Block 324 of 886 compressed\n",
            "Block 325 of 886 compressed\n",
            "Iteration 33000, Validation score = 0.9812999963760376, Training score = 0.97265625, Loss = 0.1815929263830185, KL-Loss = 0.09338679909706116, KL_2 = 45.73838974893637\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/33000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 326 of 886 compressed\n",
            "Block 327 of 886 compressed\n",
            "Block 328 of 886 compressed\n",
            "Block 329 of 886 compressed\n",
            "Block 330 of 886 compressed\n",
            "Block 331 of 886 compressed\n",
            "Block 332 of 886 compressed\n",
            "Block 333 of 886 compressed\n",
            "Block 334 of 886 compressed\n",
            "Block 335 of 886 compressed\n",
            "Iteration 34000, Validation score = 0.9814400017261505, Training score = 0.96484375, Loss = 0.16597269475460052, KL-Loss = 0.09097996354103088, KL_2 = 45.59453795630989\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/34000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 336 of 886 compressed\n",
            "Block 337 of 886 compressed\n",
            "Block 338 of 886 compressed\n",
            "Block 339 of 886 compressed\n",
            "Block 340 of 886 compressed\n",
            "Block 341 of 886 compressed\n",
            "Block 342 of 886 compressed\n",
            "Block 343 of 886 compressed\n",
            "Block 344 of 886 compressed\n",
            "Block 345 of 886 compressed\n",
            "Iteration 35000, Validation score = 0.9820399940013885, Training score = 0.98046875, Loss = 0.164638489484787, KL-Loss = 0.08934959769248962, KL_2 = 45.418711149234994\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/35000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 346 of 886 compressed\n",
            "Block 347 of 886 compressed\n",
            "Block 348 of 886 compressed\n",
            "Block 349 of 886 compressed\n",
            "Block 350 of 886 compressed\n",
            "Block 351 of 886 compressed\n",
            "Block 352 of 886 compressed\n",
            "Block 353 of 886 compressed\n",
            "Block 354 of 886 compressed\n",
            "Block 355 of 886 compressed\n",
            "Iteration 36000, Validation score = 0.9833000004291534, Training score = 0.98828125, Loss = 0.1362149715423584, KL-Loss = 0.08780454099178314, KL_2 = 45.334326829693254\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/36000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 356 of 886 compressed\n",
            "Block 357 of 886 compressed\n",
            "Block 358 of 886 compressed\n",
            "Block 359 of 886 compressed\n",
            "Block 360 of 886 compressed\n",
            "Block 361 of 886 compressed\n",
            "Block 362 of 886 compressed\n",
            "Block 363 of 886 compressed\n",
            "Block 364 of 886 compressed\n",
            "Block 365 of 886 compressed\n",
            "Iteration 37000, Validation score = 0.9799799919128418, Training score = 0.984375, Loss = 0.1385401338338852, KL-Loss = 0.08469082415103912, KL_2 = 45.25620818208775\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/37000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 366 of 886 compressed\n",
            "Block 367 of 886 compressed\n",
            "Block 368 of 886 compressed\n",
            "Block 369 of 886 compressed\n",
            "Block 370 of 886 compressed\n",
            "Block 371 of 886 compressed\n",
            "Block 372 of 886 compressed\n",
            "Block 373 of 886 compressed\n",
            "Block 374 of 886 compressed\n",
            "Block 375 of 886 compressed\n",
            "Iteration 38000, Validation score = 0.9799800097942353, Training score = 0.97265625, Loss = 0.1411076933145523, KL-Loss = 0.08331018686294556, KL_2 = 45.117890103235425\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/38000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 376 of 886 compressed\n",
            "Block 377 of 886 compressed\n",
            "Block 378 of 886 compressed\n",
            "Block 379 of 886 compressed\n",
            "Block 380 of 886 compressed\n",
            "Block 381 of 886 compressed\n",
            "Block 382 of 886 compressed\n",
            "Block 383 of 886 compressed\n",
            "Block 384 of 886 compressed\n",
            "Block 385 of 886 compressed\n",
            "Iteration 39000, Validation score = 0.9849200069904327, Training score = 0.9921875, Loss = 0.10793520510196686, KL-Loss = 0.07963442802429199, KL_2 = 45.051766213631694\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/39000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 386 of 886 compressed\n",
            "Block 387 of 886 compressed\n",
            "Block 388 of 886 compressed\n",
            "Block 389 of 886 compressed\n",
            "Block 390 of 886 compressed\n",
            "Block 391 of 886 compressed\n",
            "Block 392 of 886 compressed\n",
            "Block 393 of 886 compressed\n",
            "Block 394 of 886 compressed\n",
            "Block 395 of 886 compressed\n",
            "Iteration 40000, Validation score = 0.9813999950885772, Training score = 0.9609375, Loss = 0.19221025705337524, KL-Loss = 0.07886847108602524, KL_2 = 45.00440907089011\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/40000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 396 of 886 compressed\n",
            "Block 397 of 886 compressed\n",
            "Block 398 of 886 compressed\n",
            "Block 399 of 886 compressed\n",
            "Block 400 of 886 compressed\n",
            "Block 401 of 886 compressed\n",
            "Block 402 of 886 compressed\n",
            "Block 403 of 886 compressed\n",
            "Block 404 of 886 compressed\n",
            "Block 405 of 886 compressed\n",
            "Iteration 41000, Validation score = 0.9824999928474426, Training score = 0.97265625, Loss = 0.1888350397348404, KL-Loss = 0.07750430703163147, KL_2 = 44.96559602624339\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/41000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 406 of 886 compressed\n",
            "Block 407 of 886 compressed\n",
            "Block 408 of 886 compressed\n",
            "Block 409 of 886 compressed\n",
            "Block 410 of 886 compressed\n",
            "Block 411 of 886 compressed\n",
            "Block 412 of 886 compressed\n",
            "Block 413 of 886 compressed\n",
            "Block 414 of 886 compressed\n",
            "Block 415 of 886 compressed\n",
            "Iteration 42000, Validation score = 0.9814400017261505, Training score = 0.98828125, Loss = 0.12377770245075226, KL-Loss = 0.07570140808820724, KL_2 = 44.87391689058265\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/42000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 416 of 886 compressed\n",
            "Block 417 of 886 compressed\n",
            "Block 418 of 886 compressed\n",
            "Block 419 of 886 compressed\n",
            "Block 420 of 886 compressed\n",
            "Block 421 of 886 compressed\n",
            "Block 422 of 886 compressed\n",
            "Block 423 of 886 compressed\n",
            "Block 424 of 886 compressed\n",
            "Block 425 of 886 compressed\n",
            "Iteration 43000, Validation score = 0.9824800014495849, Training score = 0.9921875, Loss = 0.10366474837064743, KL-Loss = 0.07387276738882065, KL_2 = 44.861154402027424\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/43000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 426 of 886 compressed\n",
            "Block 427 of 886 compressed\n",
            "Block 428 of 886 compressed\n",
            "Block 429 of 886 compressed\n",
            "Block 430 of 886 compressed\n",
            "Block 431 of 886 compressed\n",
            "Block 432 of 886 compressed\n",
            "Block 433 of 886 compressed\n",
            "Block 434 of 886 compressed\n",
            "Block 435 of 886 compressed\n",
            "Iteration 44000, Validation score = 0.9832599937915802, Training score = 0.98046875, Loss = 0.14333108067512512, KL-Loss = 0.07307711988687515, KL_2 = 44.85851274851017\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/44000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 436 of 886 compressed\n",
            "Block 437 of 886 compressed\n",
            "Block 438 of 886 compressed\n",
            "Block 439 of 886 compressed\n",
            "Block 440 of 886 compressed\n",
            "Block 441 of 886 compressed\n",
            "Block 442 of 886 compressed\n",
            "Block 443 of 886 compressed\n",
            "Block 444 of 886 compressed\n",
            "Block 445 of 886 compressed\n",
            "Iteration 45000, Validation score = 0.9826200008392334, Training score = 0.9921875, Loss = 0.08680716156959534, KL-Loss = 0.07059367001056671, KL_2 = 44.78145626575639\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/45000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 446 of 886 compressed\n",
            "Block 447 of 886 compressed\n",
            "Block 448 of 886 compressed\n",
            "Block 449 of 886 compressed\n",
            "Block 450 of 886 compressed\n",
            "Block 451 of 886 compressed\n",
            "Block 452 of 886 compressed\n",
            "Block 453 of 886 compressed\n",
            "Block 454 of 886 compressed\n",
            "Block 455 of 886 compressed\n",
            "Iteration 46000, Validation score = 0.9835200071334839, Training score = 0.9765625, Loss = 0.16625750064849854, KL-Loss = 0.06816999614238739, KL_2 = 44.82805393311177\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/46000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 456 of 886 compressed\n",
            "Block 457 of 886 compressed\n",
            "Block 458 of 886 compressed\n",
            "Block 459 of 886 compressed\n",
            "Block 460 of 886 compressed\n",
            "Block 461 of 886 compressed\n",
            "Block 462 of 886 compressed\n",
            "Block 463 of 886 compressed\n",
            "Block 464 of 886 compressed\n",
            "Block 465 of 886 compressed\n",
            "Iteration 47000, Validation score = 0.9829599976539611, Training score = 0.9921875, Loss = 0.09501807391643524, KL-Loss = 0.06659380346536636, KL_2 = 44.784901422218475\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/47000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 466 of 886 compressed\n",
            "Block 467 of 886 compressed\n",
            "Block 468 of 886 compressed\n",
            "Block 469 of 886 compressed\n",
            "Block 470 of 886 compressed\n",
            "Block 471 of 886 compressed\n",
            "Block 472 of 886 compressed\n",
            "Block 473 of 886 compressed\n",
            "Block 474 of 886 compressed\n",
            "Block 475 of 886 compressed\n",
            "Iteration 48000, Validation score = 0.9842400014400482, Training score = 0.98046875, Loss = 0.11405806988477707, KL-Loss = 0.06642114371061325, KL_2 = 44.82840340185832\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/48000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 476 of 886 compressed\n",
            "Block 477 of 886 compressed\n",
            "Block 478 of 886 compressed\n",
            "Block 479 of 886 compressed\n",
            "Block 480 of 886 compressed\n",
            "Block 481 of 886 compressed\n",
            "Block 482 of 886 compressed\n",
            "Block 483 of 886 compressed\n",
            "Block 484 of 886 compressed\n",
            "Block 485 of 886 compressed\n",
            "Iteration 49000, Validation score = 0.9827800035476685, Training score = 0.99609375, Loss = 0.0975487232208252, KL-Loss = 0.06465562433004379, KL_2 = 44.80000562654785\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/49000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 486 of 886 compressed\n",
            "Block 487 of 886 compressed\n",
            "Block 488 of 886 compressed\n",
            "Block 489 of 886 compressed\n",
            "Block 490 of 886 compressed\n",
            "Block 491 of 886 compressed\n",
            "Block 492 of 886 compressed\n",
            "Block 493 of 886 compressed\n",
            "Block 494 of 886 compressed\n",
            "Block 495 of 886 compressed\n",
            "Iteration 50000, Validation score = 0.9831000089645385, Training score = 0.984375, Loss = 0.10449846088886261, KL-Loss = 0.061998460441827774, KL_2 = 44.77211416816152\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/50000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 496 of 886 compressed\n",
            "Block 497 of 886 compressed\n",
            "Block 498 of 886 compressed\n",
            "Block 499 of 886 compressed\n",
            "Block 500 of 886 compressed\n",
            "Block 501 of 886 compressed\n",
            "Block 502 of 886 compressed\n",
            "Block 503 of 886 compressed\n",
            "Block 504 of 886 compressed\n",
            "Block 505 of 886 compressed\n",
            "Iteration 51000, Validation score = 0.9830999970436096, Training score = 0.9921875, Loss = 0.09308220446109772, KL-Loss = 0.05997152626514435, KL_2 = 44.77082361034945\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/51000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 506 of 886 compressed\n",
            "Block 507 of 886 compressed\n",
            "Block 508 of 886 compressed\n",
            "Block 509 of 886 compressed\n",
            "Block 510 of 886 compressed\n",
            "Block 511 of 886 compressed\n",
            "Block 512 of 886 compressed\n",
            "Block 513 of 886 compressed\n",
            "Block 514 of 886 compressed\n",
            "Block 515 of 886 compressed\n",
            "Iteration 52000, Validation score = 0.9820600092411041, Training score = 0.98828125, Loss = 0.09837676584720612, KL-Loss = 0.056760989129543304, KL_2 = 44.80505503717718\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/52000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 516 of 886 compressed\n",
            "Block 517 of 886 compressed\n",
            "Block 518 of 886 compressed\n",
            "Block 519 of 886 compressed\n",
            "Block 520 of 886 compressed\n",
            "Block 521 of 886 compressed\n",
            "Block 522 of 886 compressed\n",
            "Block 523 of 886 compressed\n",
            "Block 524 of 886 compressed\n",
            "Block 525 of 886 compressed\n",
            "Iteration 53000, Validation score = 0.9829400062561036, Training score = 0.95703125, Loss = 0.17561516165733337, KL-Loss = 0.05507056415081024, KL_2 = 44.79751806948577\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/53000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 526 of 886 compressed\n",
            "Block 527 of 886 compressed\n",
            "Block 528 of 886 compressed\n",
            "Block 529 of 886 compressed\n",
            "Block 530 of 886 compressed\n",
            "Block 531 of 886 compressed\n",
            "Block 532 of 886 compressed\n",
            "Block 533 of 886 compressed\n",
            "Block 534 of 886 compressed\n",
            "Block 535 of 886 compressed\n",
            "Iteration 54000, Validation score = 0.9849000036716461, Training score = 0.98828125, Loss = 0.09741093218326569, KL-Loss = 0.05483895540237427, KL_2 = 44.85175451826186\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/54000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 536 of 886 compressed\n",
            "Block 537 of 886 compressed\n",
            "Block 538 of 886 compressed\n",
            "Block 539 of 886 compressed\n",
            "Block 540 of 886 compressed\n",
            "Block 541 of 886 compressed\n",
            "Block 542 of 886 compressed\n",
            "Block 543 of 886 compressed\n",
            "Block 544 of 886 compressed\n",
            "Block 545 of 886 compressed\n",
            "Iteration 55000, Validation score = 0.984960001707077, Training score = 0.98828125, Loss = 0.0993313267827034, KL-Loss = 0.05218464136123657, KL_2 = 44.78280736146157\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/55000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 546 of 886 compressed\n",
            "Block 547 of 886 compressed\n",
            "Block 548 of 886 compressed\n",
            "Block 549 of 886 compressed\n",
            "Block 550 of 886 compressed\n",
            "Block 551 of 886 compressed\n",
            "Block 552 of 886 compressed\n",
            "Block 553 of 886 compressed\n",
            "Block 554 of 886 compressed\n",
            "Block 555 of 886 compressed\n",
            "Iteration 56000, Validation score = 0.9837400019168854, Training score = 1.0, Loss = 0.06345723569393158, KL-Loss = 0.05179794505238533, KL_2 = 44.79669255276163\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/56000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 556 of 886 compressed\n",
            "Block 557 of 886 compressed\n",
            "Block 558 of 886 compressed\n",
            "Block 559 of 886 compressed\n",
            "Block 560 of 886 compressed\n",
            "Block 561 of 886 compressed\n",
            "Block 562 of 886 compressed\n",
            "Block 563 of 886 compressed\n",
            "Block 564 of 886 compressed\n",
            "Block 565 of 886 compressed\n",
            "Iteration 57000, Validation score = 0.9845600008964539, Training score = 0.9921875, Loss = 0.07513242959976196, KL-Loss = 0.050014082342386246, KL_2 = 44.77943374978224\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/57000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 566 of 886 compressed\n",
            "Block 567 of 886 compressed\n",
            "Block 568 of 886 compressed\n",
            "Block 569 of 886 compressed\n",
            "Block 570 of 886 compressed\n",
            "Block 571 of 886 compressed\n",
            "Block 572 of 886 compressed\n",
            "Block 573 of 886 compressed\n",
            "Block 574 of 886 compressed\n",
            "Block 575 of 886 compressed\n",
            "Iteration 58000, Validation score = 0.9858400046825408, Training score = 0.984375, Loss = 0.08441364020109177, KL-Loss = 0.04751593619585037, KL_2 = 44.75811065279767\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/58000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 576 of 886 compressed\n",
            "Block 577 of 886 compressed\n",
            "Block 578 of 886 compressed\n",
            "Block 579 of 886 compressed\n",
            "Block 580 of 886 compressed\n",
            "Block 581 of 886 compressed\n",
            "Block 582 of 886 compressed\n",
            "Block 583 of 886 compressed\n",
            "Block 584 of 886 compressed\n",
            "Block 585 of 886 compressed\n",
            "Iteration 59000, Validation score = 0.9857000052928925, Training score = 0.98828125, Loss = 0.0798419713973999, KL-Loss = 0.046572376042604446, KL_2 = 44.82080314455139\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/59000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 586 of 886 compressed\n",
            "Block 587 of 886 compressed\n",
            "Block 588 of 886 compressed\n",
            "Block 589 of 886 compressed\n",
            "Block 590 of 886 compressed\n",
            "Block 591 of 886 compressed\n",
            "Block 592 of 886 compressed\n",
            "Block 593 of 886 compressed\n",
            "Block 594 of 886 compressed\n",
            "Block 595 of 886 compressed\n",
            "Iteration 60000, Validation score = 0.9841000080108643, Training score = 0.9921875, Loss = 0.08026565611362457, KL-Loss = 0.04548509046435356, KL_2 = 44.81054197167031\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/60000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 596 of 886 compressed\n",
            "Block 597 of 886 compressed\n",
            "Block 598 of 886 compressed\n",
            "Block 599 of 886 compressed\n",
            "Block 600 of 886 compressed\n",
            "Block 601 of 886 compressed\n",
            "Block 602 of 886 compressed\n",
            "Block 603 of 886 compressed\n",
            "Block 604 of 886 compressed\n",
            "Block 605 of 886 compressed\n",
            "Iteration 61000, Validation score = 0.9853000104427337, Training score = 0.984375, Loss = 0.08814148604869843, KL-Loss = 0.04287633299827576, KL_2 = 44.82335123950657\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/61000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 606 of 886 compressed\n",
            "Block 607 of 886 compressed\n",
            "Block 608 of 886 compressed\n",
            "Block 609 of 886 compressed\n",
            "Block 610 of 886 compressed\n",
            "Block 611 of 886 compressed\n",
            "Block 612 of 886 compressed\n",
            "Block 613 of 886 compressed\n",
            "Block 614 of 886 compressed\n",
            "Block 615 of 886 compressed\n",
            "Iteration 62000, Validation score = 0.9840800046920777, Training score = 0.9765625, Loss = 0.11168763041496277, KL-Loss = 0.04259064421057701, KL_2 = 44.87092301659643\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/62000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 616 of 886 compressed\n",
            "Block 617 of 886 compressed\n",
            "Block 618 of 886 compressed\n",
            "Block 619 of 886 compressed\n",
            "Block 620 of 886 compressed\n",
            "Block 621 of 886 compressed\n",
            "Block 622 of 886 compressed\n",
            "Block 623 of 886 compressed\n",
            "Block 624 of 886 compressed\n",
            "Block 625 of 886 compressed\n",
            "Iteration 63000, Validation score = 0.9838800013065339, Training score = 0.9921875, Loss = 0.05562576651573181, KL-Loss = 0.0406150221824646, KL_2 = 44.8467381283015\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/63000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 626 of 886 compressed\n",
            "Block 627 of 886 compressed\n",
            "Block 628 of 886 compressed\n",
            "Block 629 of 886 compressed\n",
            "Block 630 of 886 compressed\n",
            "Block 631 of 886 compressed\n",
            "Block 632 of 886 compressed\n",
            "Block 633 of 886 compressed\n",
            "Block 634 of 886 compressed\n",
            "Block 635 of 886 compressed\n",
            "Iteration 64000, Validation score = 0.9855399966239929, Training score = 0.97265625, Loss = 0.14950266480445862, KL-Loss = 0.038258396089076996, KL_2 = 44.849665960949785\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/64000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 636 of 886 compressed\n",
            "Block 637 of 886 compressed\n",
            "Block 638 of 886 compressed\n",
            "Block 639 of 886 compressed\n",
            "Block 640 of 886 compressed\n",
            "Block 641 of 886 compressed\n",
            "Block 642 of 886 compressed\n",
            "Block 643 of 886 compressed\n",
            "Block 644 of 886 compressed\n",
            "Block 645 of 886 compressed\n",
            "Iteration 65000, Validation score = 0.9859600007534027, Training score = 0.9921875, Loss = 0.07798518240451813, KL-Loss = 0.03591685742139816, KL_2 = 44.9084097310397\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/65000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 646 of 886 compressed\n",
            "Block 647 of 886 compressed\n",
            "Block 648 of 886 compressed\n",
            "Block 649 of 886 compressed\n",
            "Block 650 of 886 compressed\n",
            "Block 651 of 886 compressed\n",
            "Block 652 of 886 compressed\n",
            "Block 653 of 886 compressed\n",
            "Block 654 of 886 compressed\n",
            "Block 655 of 886 compressed\n",
            "Iteration 66000, Validation score = 0.9846399962902069, Training score = 0.99609375, Loss = 0.05169392004609108, KL-Loss = 0.03604226931929588, KL_2 = 44.954192888560584\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/66000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 656 of 886 compressed\n",
            "Block 657 of 886 compressed\n",
            "Block 658 of 886 compressed\n",
            "Block 659 of 886 compressed\n",
            "Block 660 of 886 compressed\n",
            "Block 661 of 886 compressed\n",
            "Block 662 of 886 compressed\n",
            "Block 663 of 886 compressed\n",
            "Block 664 of 886 compressed\n",
            "Block 665 of 886 compressed\n",
            "Iteration 67000, Validation score = 0.9854599952697753, Training score = 0.9921875, Loss = 0.057447806000709534, KL-Loss = 0.03333774209022522, KL_2 = 44.953540730348514\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/67000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 666 of 886 compressed\n",
            "Block 667 of 886 compressed\n",
            "Block 668 of 886 compressed\n",
            "Block 669 of 886 compressed\n",
            "Block 670 of 886 compressed\n",
            "Block 671 of 886 compressed\n",
            "Block 672 of 886 compressed\n",
            "Block 673 of 886 compressed\n",
            "Block 674 of 886 compressed\n",
            "Block 675 of 886 compressed\n",
            "Iteration 68000, Validation score = 0.9854400038719178, Training score = 0.99609375, Loss = 0.048238612711429596, KL-Loss = 0.0319095179438591, KL_2 = 44.96923930671927\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/68000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 676 of 886 compressed\n",
            "Block 677 of 886 compressed\n",
            "Block 678 of 886 compressed\n",
            "Block 679 of 886 compressed\n",
            "Block 680 of 886 compressed\n",
            "Block 681 of 886 compressed\n",
            "Block 682 of 886 compressed\n",
            "Block 683 of 886 compressed\n",
            "Block 684 of 886 compressed\n",
            "Block 685 of 886 compressed\n",
            "Iteration 69000, Validation score = 0.9861599981784821, Training score = 0.984375, Loss = 0.0749640166759491, KL-Loss = 0.030316373333334923, KL_2 = 45.00066672840733\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/69000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 686 of 886 compressed\n",
            "Block 687 of 886 compressed\n",
            "Block 688 of 886 compressed\n",
            "Block 689 of 886 compressed\n",
            "Block 690 of 886 compressed\n",
            "Block 691 of 886 compressed\n",
            "Block 692 of 886 compressed\n",
            "Block 693 of 886 compressed\n",
            "Block 694 of 886 compressed\n",
            "Block 695 of 886 compressed\n",
            "Iteration 70000, Validation score = 0.9861000061035157, Training score = 0.9921875, Loss = 0.057157471776008606, KL-Loss = 0.029034653678536415, KL_2 = 44.99061468642971\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/70000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 696 of 886 compressed\n",
            "Block 697 of 886 compressed\n",
            "Block 698 of 886 compressed\n",
            "Block 699 of 886 compressed\n",
            "Block 700 of 886 compressed\n",
            "Block 701 of 886 compressed\n",
            "Block 702 of 886 compressed\n",
            "Block 703 of 886 compressed\n",
            "Block 704 of 886 compressed\n",
            "Block 705 of 886 compressed\n",
            "Iteration 71000, Validation score = 0.9853799998760223, Training score = 0.9921875, Loss = 0.05293961986899376, KL-Loss = 0.02782200463116169, KL_2 = 45.0449116730989\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/71000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 706 of 886 compressed\n",
            "Block 707 of 886 compressed\n",
            "Block 708 of 886 compressed\n",
            "Block 709 of 886 compressed\n",
            "Block 710 of 886 compressed\n",
            "Block 711 of 886 compressed\n",
            "Block 712 of 886 compressed\n",
            "Block 713 of 886 compressed\n",
            "Block 714 of 886 compressed\n",
            "Block 715 of 886 compressed\n",
            "Iteration 72000, Validation score = 0.9854399919509887, Training score = 0.98828125, Loss = 0.06562592834234238, KL-Loss = 0.02682896889746189, KL_2 = 45.04447690095753\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/72000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 716 of 886 compressed\n",
            "Block 717 of 886 compressed\n",
            "Block 718 of 886 compressed\n",
            "Block 719 of 886 compressed\n",
            "Block 720 of 886 compressed\n",
            "Block 721 of 886 compressed\n",
            "Block 722 of 886 compressed\n",
            "Block 723 of 886 compressed\n",
            "Block 724 of 886 compressed\n",
            "Block 725 of 886 compressed\n",
            "Iteration 73000, Validation score = 0.9864799976348877, Training score = 0.99609375, Loss = 0.04299101233482361, KL-Loss = 0.02394234575331211, KL_2 = 45.00647836614529\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/73000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 726 of 886 compressed\n",
            "Block 727 of 886 compressed\n",
            "Block 728 of 886 compressed\n",
            "Block 729 of 886 compressed\n",
            "Block 730 of 886 compressed\n",
            "Block 731 of 886 compressed\n",
            "Block 732 of 886 compressed\n",
            "Block 733 of 886 compressed\n",
            "Block 734 of 886 compressed\n",
            "Block 735 of 886 compressed\n",
            "Iteration 74000, Validation score = 0.9863799989223481, Training score = 0.9765625, Loss = 0.06449320167303085, KL-Loss = 0.02314782328903675, KL_2 = 45.11048521821988\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/74000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 736 of 886 compressed\n",
            "Block 737 of 886 compressed\n",
            "Block 738 of 886 compressed\n",
            "Block 739 of 886 compressed\n",
            "Block 740 of 886 compressed\n",
            "Block 741 of 886 compressed\n",
            "Block 742 of 886 compressed\n",
            "Block 743 of 886 compressed\n",
            "Block 744 of 886 compressed\n",
            "Block 745 of 886 compressed\n",
            "Iteration 75000, Validation score = 0.9857599914073945, Training score = 0.984375, Loss = 0.06347262859344482, KL-Loss = 0.021888816729187965, KL_2 = 45.13752639438034\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/75000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 746 of 886 compressed\n",
            "Block 747 of 886 compressed\n",
            "Block 748 of 886 compressed\n",
            "Block 749 of 886 compressed\n",
            "Block 750 of 886 compressed\n",
            "Block 751 of 886 compressed\n",
            "Block 752 of 886 compressed\n",
            "Block 753 of 886 compressed\n",
            "Block 754 of 886 compressed\n",
            "Block 755 of 886 compressed\n",
            "Iteration 76000, Validation score = 0.9866999924182892, Training score = 0.984375, Loss = 0.07290655374526978, KL-Loss = 0.020686570554971695, KL_2 = 45.11676189704576\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/76000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 756 of 886 compressed\n",
            "Block 757 of 886 compressed\n",
            "Block 758 of 886 compressed\n",
            "Block 759 of 886 compressed\n",
            "Block 760 of 886 compressed\n",
            "Block 761 of 886 compressed\n",
            "Block 762 of 886 compressed\n",
            "Block 763 of 886 compressed\n",
            "Block 764 of 886 compressed\n",
            "Block 765 of 886 compressed\n",
            "Iteration 77000, Validation score = 0.9872000038623809, Training score = 0.98828125, Loss = 0.058108046650886536, KL-Loss = 0.019451720640063286, KL_2 = 45.19977585882543\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/77000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 766 of 886 compressed\n",
            "Block 767 of 886 compressed\n",
            "Block 768 of 886 compressed\n",
            "Block 769 of 886 compressed\n",
            "Block 770 of 886 compressed\n",
            "Block 771 of 886 compressed\n",
            "Block 772 of 886 compressed\n",
            "Block 773 of 886 compressed\n",
            "Block 774 of 886 compressed\n",
            "Block 775 of 886 compressed\n",
            "Iteration 78000, Validation score = 0.9875200033187866, Training score = 0.99609375, Loss = 0.03617071360349655, KL-Loss = 0.01782776415348053, KL_2 = 45.27285885441368\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/78000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 776 of 886 compressed\n",
            "Block 777 of 886 compressed\n",
            "Block 778 of 886 compressed\n",
            "Block 779 of 886 compressed\n",
            "Block 780 of 886 compressed\n",
            "Block 781 of 886 compressed\n",
            "Block 782 of 886 compressed\n",
            "Block 783 of 886 compressed\n",
            "Block 784 of 886 compressed\n",
            "Block 785 of 886 compressed\n",
            "Iteration 79000, Validation score = 0.9877400040626526, Training score = 0.9921875, Loss = 0.03796848654747009, KL-Loss = 0.01605628989636898, KL_2 = 45.229422916111766\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/79000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 786 of 886 compressed\n",
            "Block 787 of 886 compressed\n",
            "Block 788 of 886 compressed\n",
            "Block 789 of 886 compressed\n",
            "Block 790 of 886 compressed\n",
            "Block 791 of 886 compressed\n",
            "Block 792 of 886 compressed\n",
            "Block 793 of 886 compressed\n",
            "Block 794 of 886 compressed\n",
            "Block 795 of 886 compressed\n",
            "Iteration 80000, Validation score = 0.9876199960708618, Training score = 0.9921875, Loss = 0.04106702283024788, KL-Loss = 0.015003702603280544, KL_2 = 45.2950487439586\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/80000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 796 of 886 compressed\n",
            "Block 797 of 886 compressed\n",
            "Block 798 of 886 compressed\n",
            "Block 799 of 886 compressed\n",
            "Block 800 of 886 compressed\n",
            "Block 801 of 886 compressed\n",
            "Block 802 of 886 compressed\n",
            "Block 803 of 886 compressed\n",
            "Block 804 of 886 compressed\n",
            "Block 805 of 886 compressed\n",
            "Iteration 81000, Validation score = 0.9879800140857696, Training score = 0.984375, Loss = 0.07104504853487015, KL-Loss = 0.013717164285480976, KL_2 = 45.35534173376748\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/81000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 806 of 886 compressed\n",
            "Block 807 of 886 compressed\n",
            "Block 808 of 886 compressed\n",
            "Block 809 of 886 compressed\n",
            "Block 810 of 886 compressed\n",
            "Block 811 of 886 compressed\n",
            "Block 812 of 886 compressed\n",
            "Block 813 of 886 compressed\n",
            "Block 814 of 886 compressed\n",
            "Block 815 of 886 compressed\n",
            "Iteration 82000, Validation score = 0.9880800068378448, Training score = 0.99609375, Loss = 0.03875613957643509, KL-Loss = 0.012366208247840405, KL_2 = 45.374452445931354\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/82000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 816 of 886 compressed\n",
            "Block 817 of 886 compressed\n",
            "Block 818 of 886 compressed\n",
            "Block 819 of 886 compressed\n",
            "Block 820 of 886 compressed\n",
            "Block 821 of 886 compressed\n",
            "Block 822 of 886 compressed\n",
            "Block 823 of 886 compressed\n",
            "Block 824 of 886 compressed\n",
            "Block 825 of 886 compressed\n",
            "Iteration 83000, Validation score = 0.9875400006771088, Training score = 0.9921875, Loss = 0.036059439182281494, KL-Loss = 0.011096589267253876, KL_2 = 45.44801974466443\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/83000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 826 of 886 compressed\n",
            "Block 827 of 886 compressed\n",
            "Block 828 of 886 compressed\n",
            "Block 829 of 886 compressed\n",
            "Block 830 of 886 compressed\n",
            "Block 831 of 886 compressed\n",
            "Block 832 of 886 compressed\n",
            "Block 833 of 886 compressed\n",
            "Block 834 of 886 compressed\n",
            "Block 835 of 886 compressed\n",
            "Iteration 84000, Validation score = 0.9877399981021882, Training score = 0.9921875, Loss = 0.03218022361397743, KL-Loss = 0.010201803408563137, KL_2 = 45.47244128108695\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/84000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 836 of 886 compressed\n",
            "Block 837 of 886 compressed\n",
            "Block 838 of 886 compressed\n",
            "Block 839 of 886 compressed\n",
            "Block 840 of 886 compressed\n",
            "Block 841 of 886 compressed\n",
            "Block 842 of 886 compressed\n",
            "Block 843 of 886 compressed\n",
            "Block 844 of 886 compressed\n",
            "Block 845 of 886 compressed\n",
            "Iteration 85000, Validation score = 0.9869400084018707, Training score = 0.9921875, Loss = 0.033457715064287186, KL-Loss = 0.00785661581903696, KL_2 = 45.49394048830601\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/85000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 846 of 886 compressed\n",
            "Block 847 of 886 compressed\n",
            "Block 848 of 886 compressed\n",
            "Block 849 of 886 compressed\n",
            "Block 850 of 886 compressed\n",
            "Block 851 of 886 compressed\n",
            "Block 852 of 886 compressed\n",
            "Block 853 of 886 compressed\n",
            "Block 854 of 886 compressed\n",
            "Block 855 of 886 compressed\n",
            "Iteration 86000, Validation score = 0.9875399947166443, Training score = 0.99609375, Loss = 0.02285410836338997, KL-Loss = 0.006162258796393871, KL_2 = 45.57536945797533\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/86000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 856 of 886 compressed\n",
            "Block 857 of 886 compressed\n",
            "Block 858 of 886 compressed\n",
            "Block 859 of 886 compressed\n",
            "Block 860 of 886 compressed\n",
            "Block 861 of 886 compressed\n",
            "Block 862 of 886 compressed\n",
            "Block 863 of 886 compressed\n",
            "Block 864 of 886 compressed\n",
            "Block 865 of 886 compressed\n",
            "Iteration 87000, Validation score = 0.9879800081253052, Training score = 0.98046875, Loss = 0.07548310607671738, KL-Loss = 0.004531032871454954, KL_2 = 45.86364540149036\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/87000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 866 of 886 compressed\n",
            "Block 867 of 886 compressed\n",
            "Block 868 of 886 compressed\n",
            "Block 869 of 886 compressed\n",
            "Block 870 of 886 compressed\n",
            "Block 871 of 886 compressed\n",
            "Block 872 of 886 compressed\n",
            "Block 873 of 886 compressed\n",
            "Block 874 of 886 compressed\n",
            "Block 875 of 886 compressed\n",
            "Iteration 88000, Validation score = 0.9881200015544891, Training score = 1.0, Loss = 0.03125298023223877, KL-Loss = 0.0030540795996785164, KL_2 = 46.09991379138447\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/88000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "Block 876 of 886 compressed\n",
            "Block 877 of 886 compressed\n",
            "Block 878 of 886 compressed\n",
            "Block 879 of 886 compressed\n",
            "Block 880 of 886 compressed\n",
            "Block 881 of 886 compressed\n",
            "Block 882 of 886 compressed\n",
            "Block 883 of 886 compressed\n",
            "Block 884 of 886 compressed\n",
            "Block 885 of 886 compressed\n",
            "Iteration 89000, Validation score = 0.9878000020980835, Training score = 1.0, Loss = 0.019878815859556198, KL-Loss = 0.0, KL_2 = 45.47850057384215\n",
            "INFO:tensorflow:/scratch/mh740/compression_models/Lenet5/compression/89000.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
            "0.9878000020980835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGr1qh_NaK2"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}